# Arxiv SNN Paper Weekly


 ### **Last 5 working days (Updated on 2025-05-21)** 


- FireFly-T: High-Throughput Sparsity Exploitation for Spiking Transformer Acceleration with Dual-Engine Overlay Architecture [[arxiv](https://arxiv.org/abs/2505.12771)]

- SPKLIP: Aligning Spike Video Streams with Natural Language [[arxiv](https://arxiv.org/abs/2505.12656)] [[paper with code](https://paperswithcode.com/paper/spklip-aligning-spike-video-streams-with)]

- Spiking Neural Network: a low power solution for physical layer authentication [[arxiv](https://arxiv.org/abs/2505.12647)] [[paper with code](https://paperswithcode.com/paper/spiking-neural-network-a-low-power-solution)]

- SpikeX: Exploring Accelerator Architecture and Network-Hardware Co-Optimization for Sparse Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2505.12292)] [[paper with code](https://paperswithcode.com/paper/spikex-exploring-accelerator-architecture-and)]

- Bishop: Sparsified Bundling Spiking Transformers on Heterogeneous Cores with Error-Constrained Pruning [[arxiv](https://arxiv.org/abs/2505.12281)] [[paper with code](https://paperswithcode.com/paper/bishop-sparsified-bundling-spiking)]

- Adaptive Gradient Learning for Spiking Neural Networks by Exploiting Membrane Potential Dynamics [[arxiv](https://arxiv.org/abs/2505.11863)] [[paper with code](https://paperswithcode.com/paper/adaptive-gradient-learning-for-spiking-neural)]

- ASRC-SNN: Adaptive Skip Recurrent Connection Spiking Neural Network [[arxiv](https://arxiv.org/abs/2505.11455)] [[paper with code](https://paperswithcode.com/paper/2505-11455)]

- Energy efficiency analysis of Spiking Neural Networks for space applications [[arxiv](https://arxiv.org/abs/2505.11418)] [[paper with code](https://paperswithcode.com/paper/2505-11418)]

- Lightweight LIF-only SNN accelerator using differential time encoding [[arxiv](https://arxiv.org/abs/2505.11252)] [[paper with code](https://paperswithcode.com/paper/2505-11252)]

- STEP: A Unified Spiking Transformer Evaluation Platform for Fair and Reproducible Benchmarking [[arxiv](https://arxiv.org/abs/2505.11151)] [[paper with code](https://paperswithcode.com/paper/2505-11151)]

- Towards Robust Spiking Neural Networks:Mitigating Heterogeneous Training Vulnerability via Dominant Eigencomponent Projection [[arxiv](https://arxiv.org/abs/2505.11134)] [[paper with code](https://paperswithcode.com/paper/2505-11134)]

- Phi: Leveraging Pattern-based Hierarchical Sparsity for High-Efficiency Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2505.10909)] [[paper with code](https://paperswithcode.com/paper/phi-leveraging-pattern-based-hierarchical)]

- ILIF: Temporal Inhibitory Leaky Integrate-and-Fire Neuron for Overactivation in Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2505.10371)] [[paper with code](https://paperswithcode.com/paper/ilif-temporal-inhibitory-leaky-integrate-and)]

- Plasticity as the Mirror of Empowerment [[arxiv](https://arxiv.org/abs/2505.10361)] [[paper with code](https://paperswithcode.com/paper/plasticity-as-the-mirror-of-empowerment)]

- SpikeVideoFormer: An Efficient Spike-Driven Video Transformer with Hamming Attention and $\mathcal{O}(T)$ Complexity [[arxiv](https://arxiv.org/abs/2505.10352)] [[paper with code](https://paperswithcode.com/paper/spikevideoformer-an-efficient-spike-driven)]

- Spike-timing-dependent Hebbian learning as noisy gradient descent [[arxiv](https://arxiv.org/abs/2505.10272)] [[paper with code](https://paperswithcode.com/paper/spike-timing-dependent-hebbian-learning-as)]

- LAS: Loss-less ANN-SNN Conversion for Fully Spike-Driven Large Language Models [[arxiv](https://arxiv.org/abs/2505.09659)] [[paper with code](https://paperswithcode.com/paper/las-loss-less-ann-snn-conversion-for-fully)] [[code](https://github.com/lc783/las)]

- Preserving Plasticity in Continual Learning with Adaptive Linearity Injection [[arxiv](https://arxiv.org/abs/2505.09486)] [[paper with code](https://paperswithcode.com/paper/preserving-plasticity-in-continual-learning)]

- Convolutional Spiking Neural Network for Image Classification [[arxiv](https://arxiv.org/abs/2505.08514)]

- Self-cross Feature based Spiking Neural Networks for Efficient Few-shot Learning [[arxiv](https://arxiv.org/abs/2505.07921)] [[paper with code](https://paperswithcode.com/paper/self-cross-feature-based-spiking-neural)]

