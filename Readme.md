# Arxiv SNN Paper Weekly


 ### **Last 5 working days (Updated on 2025-05-27)** 


- SpikeGen: Generative Framework for Visual Spike Stream Processing [[arxiv](https://arxiv.org/abs/2505.18049)]

- Time to Spike? Understanding the Representational Power of Spiking Neural Networks in Discrete Time [[arxiv](https://arxiv.org/abs/2505.18023)]

- A Principled Bayesian Framework for Training Binary and Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2505.17962)]

- SVL: Spike-based Vision-language Pretraining for Efficient 3D Open-world Understanding [[arxiv](https://arxiv.org/abs/2505.17674)]

- TDFormer: A Top-Down Attention-Controlled Spiking Transformer [[arxiv](https://arxiv.org/abs/2505.15840)] [[paper with code](https://paperswithcode.com/paper/tdformer-a-top-down-attention-controlled)]

- Adversarially Robust Spiking Neural Networks with Sparse Connectivity [[arxiv](https://arxiv.org/abs/2505.15833)] [[paper with code](https://paperswithcode.com/paper/adversarially-robust-spiking-neural-networks-1)]

- Beyond Pairwise Plasticity: Group-Level Spike Synchrony Facilitates Efficient Learning in Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2505.14841)] [[paper with code](https://paperswithcode.com/paper/beyond-pairwise-plasticity-group-level-spike)]

- MSVIT: Improving Spiking Vision Transformer Using Multi-scale Attention Fusion [[arxiv](https://arxiv.org/abs/2505.14719)] [[paper with code](https://paperswithcode.com/paper/msvit-improving-spiking-vision-transformer)]

- Spiking Neural Networks with Temporal Attention-Guided Adaptive Fusion for imbalanced Multi-modal Learning [[arxiv](https://arxiv.org/abs/2505.14535)] [[paper with code](https://paperswithcode.com/paper/spiking-neural-networks-with-temporal)]

- Energy-Efficient Deep Reinforcement Learning with Spiking Transformers [[arxiv](https://arxiv.org/abs/2505.14533)] [[paper with code](https://paperswithcode.com/paper/energy-efficient-deep-reinforcement-learning)]

- Frozen Backpropagation: Relaxing Weight Symmetry in Temporally-Coded Deep Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2505.13741)] [[paper with code](https://paperswithcode.com/paper/frozen-backpropagation-relaxing-weight)] [[code](https://gitlab.univ-lille.fr/fox/fbp)]

- Spiking Neural Networks with Random Network Architecture [[arxiv](https://arxiv.org/abs/2505.13622)]

- FireFly-T: High-Throughput Sparsity Exploitation for Spiking Transformer Acceleration with Dual-Engine Overlay Architecture [[arxiv](https://arxiv.org/abs/2505.12771)]

- SPKLIP: Aligning Spike Video Streams with Natural Language [[arxiv](https://arxiv.org/abs/2505.12656)] [[paper with code](https://paperswithcode.com/paper/spklip-aligning-spike-video-streams-with)]

- Spiking Neural Network: a low power solution for physical layer authentication [[arxiv](https://arxiv.org/abs/2505.12647)] [[paper with code](https://paperswithcode.com/paper/spiking-neural-network-a-low-power-solution)]

- SpikeX: Exploring Accelerator Architecture and Network-Hardware Co-Optimization for Sparse Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2505.12292)] [[paper with code](https://paperswithcode.com/paper/spikex-exploring-accelerator-architecture-and)]

- Bishop: Sparsified Bundling Spiking Transformers on Heterogeneous Cores with Error-Constrained Pruning [[arxiv](https://arxiv.org/abs/2505.12281)] [[paper with code](https://paperswithcode.com/paper/bishop-sparsified-bundling-spiking)]

- Adaptive Gradient Learning for Spiking Neural Networks by Exploiting Membrane Potential Dynamics [[arxiv](https://arxiv.org/abs/2505.11863)] [[paper with code](https://paperswithcode.com/paper/adaptive-gradient-learning-for-spiking-neural)]

