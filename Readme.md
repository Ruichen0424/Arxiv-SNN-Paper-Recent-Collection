# Arxiv SNN Paper Weekly


 ### **Last 5 working days (Updated on 2025-08-11)** 


- Divide-and-Conquer for Enhancing Unlabeled Learning, Stability, and Plasticity in Semi-supervised Continual Learning [[arxiv](https://arxiv.org/abs/2508.05316)]

- S$^2$M-Former: Spiking Symmetric Mixing Branchformer for Brain Auditory Attention Detection [[arxiv](https://arxiv.org/abs/2508.05164)]

- Harmonic fractal transformation for modeling complex neuronal effects: from bursting and noise shaping to waveform sensitivity and noise-induced subthreshold spiking [[arxiv](https://arxiv.org/abs/2508.05341)]

- TDSNNs: Competitive Topographic Deep Spiking Neural Networks for Visual Cortex Modeling [[arxiv](https://arxiv.org/abs/2508.04270)]

- Measuring the stability and plasticity of recommender systems [[arxiv](https://arxiv.org/abs/2508.03941)]

- FlashCommunication V2: Bit Splitting and Spike Reserving for Any Bit Communication [[arxiv](https://arxiv.org/abs/2508.03760)]

- Exploring Stability-Plasticity Trade-offs for Continual Named Entity Recognition [[arxiv](https://arxiv.org/abs/2508.03259)]

- Ultralight Polarity-Split Neuromorphic SNN for Event-Stream Super-Resolution [[arxiv](https://arxiv.org/abs/2508.03244)]

- SpikeSTAG: Spatial-Temporal Forecasting via GNN-SNN Collaboration [[arxiv](https://arxiv.org/abs/2508.02069)]

- PRIME: Plasticity-Robust Incremental Model for Encrypted Traffic Classification in Dynamic Network Environments [[arxiv](https://arxiv.org/abs/2508.02031)]

- Toward Efficient Spiking Transformers: Synapse Pruning Meets Synergistic Learning-Based Compensation [[arxiv](https://arxiv.org/abs/2508.01992)]

- SPARTA: Advancing Sparse Attention in Spiking Neural Networks via Spike-Timing-Based Prioritization [[arxiv](https://arxiv.org/abs/2508.01646)]

- ParaRevSNN: A Parallel Reversible Spiking Neural Network for Efficient Training and Inference [[arxiv](https://arxiv.org/abs/2508.01223)]

- E2ATST: A Temporal-Spatial Optimized Energy-Efficient Architecture for Training Spiking Transformer [[arxiv](https://arxiv.org/abs/2508.00475)]

- STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers [[arxiv](https://arxiv.org/abs/2508.00387)]

- Reinitializing weights vs units for maintaining plasticity in neural networks [[arxiv](https://arxiv.org/abs/2508.00212)]

- Anomaly detection with spiking neural networks for LHC physics [[arxiv](https://arxiv.org/abs/2508.00063)]

