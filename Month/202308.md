# Arxiv Paper 2023-08


- Gradient Scaling on Deep Spiking Neural Networks with Spike-Dependent Local Information [[arxiv](https://arxiv.org/abs/2308.00558)] [[paper with code](https://paperswithcode.com/paper/gradient-scaling-on-deep-spiking-neural)]

- Evaluating Spiking Neural Network On Neuromorphic Platform For Human Activity Recognition [[arxiv](https://arxiv.org/abs/2308.00787)] [[paper with code](https://paperswithcode.com/paper/evaluating-spiking-neural-network-on)] [[code](https://github.com/zhaxidele/har-with-snn)]

- Paired Competing Neurons Improving STDP Supervised Local Learning In Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.02194)] [[paper with code](https://paperswithcode.com/paper/paired-competing-neurons-improving-stdp)]

- Attention-free Spikformer: Mixing Spike Sequences with Simple Linear Transforms [[arxiv](https://arxiv.org/abs/2308.02557)] [[paper with code](https://paperswithcode.com/paper/attention-free-spikformer-mixing-spike)]

- Recurrent Spike-based Image Restoration under General Illumination [[arxiv](https://arxiv.org/abs/2308.03018)] [[paper with code](https://paperswithcode.com/paper/recurrent-spike-based-image-restoration-under)] [[code](https://github.com/bit-vision/rsir)]

- An improved local radial basis function method for solving small-strain elasto-plasticity [[arxiv](https://arxiv.org/abs/2308.03817)]

- SSTFormer: Bridging Spiking Neural Network and Memory Support Transformer for Frame-Event based Recognition [[arxiv](https://arxiv.org/abs/2308.04369)] [[paper with code](https://paperswithcode.com/paper/sstformer-bridging-spiking-neural-network-and)] [[code](https://github.com/event-ahu/sstformer)]

- Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.04672)] [[paper with code](https://paperswithcode.com/paper/resource-constrained-model-compression-via)] [[code](https://github.com/chenjallen/resource-constrained-compression-on-snn)]

- Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.04749)] [[paper with code](https://paperswithcode.com/paper/enhancing-efficient-continual-learning-with)] [[code](https://github.com/braincog-x/brain-cog)]

- Bayes Risk Consistency of Nonparametric Classification Rules for Spike Trains Data [[arxiv](https://arxiv.org/abs/2308.04796)] [[paper with code](https://paperswithcode.com/paper/bayes-risk-consistency-of-nonparametric)]

- A Homomorphic Encryption Framework for Privacy-Preserving Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.05636)] [[paper with code](https://paperswithcode.com/paper/a-homomorphic-encryption-framework-for)]

- Gated Attention Coding for Training High-performance and Efficient Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.06582)] [[paper with code](https://paperswithcode.com/paper/gated-attention-coding-for-training-high)] [[code](https://github.com/bollossom/GAC)]

- RMP-Loss: Regularizing Membrane Potential Distribution for Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.06787)] [[paper with code](https://paperswithcode.com/paper/rmp-loss-regularizing-membrane-potential)] [[code](https://github.com/yfguo91/mpbn)]

- Expressivity of Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.08218)]

- HyperSNN: A new efficient and robust deep learning model for resource constrained control applications [[arxiv](https://arxiv.org/abs/2308.08222)] [[paper with code](https://paperswithcode.com/paper/hypersnn-a-new-efficient-and-robust-deep)]

- Inherent Redundancy in Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.08227)] [[paper with code](https://paperswithcode.com/paper/inherent-redundancy-in-spiking-neural)] [[code](https://github.com/biclab/asa-snn)]

- Membrane Potential Batch Normalization for Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.08359)] [[paper with code](https://paperswithcode.com/paper/membrane-potential-batch-normalization-for)] [[code](https://github.com/yfguo91/mpbn)]

- Towards Zero Memory Footprint Spiking Neural Network Training [[arxiv](https://arxiv.org/abs/2308.08649)] [[paper with code](https://paperswithcode.com/paper/towards-zero-memory-footprint-spiking-neural)]

- Pattern recognition using spiking antiferromagnetic neurons [[arxiv](https://arxiv.org/abs/2308.09071)] [[paper with code](https://paperswithcode.com/paper/pattern-recognition-using-spiking)]

- Artificial-Spiking Hierarchical Networks for Vision-Language Representation Learning [[arxiv](https://arxiv.org/abs/2308.09455)] [[paper with code](https://paperswithcode.com/paper/artificial-spiking-hierarchical-networks-for)]

- Spiking-Diffusion: Vector Quantized Discrete Diffusion Model with Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.10187)] [[paper with code](https://paperswithcode.com/paper/spiking-diffusion-vector-quantized-discrete)] [[code](https://github.com/Arktis2022/Spiking-Diffusion)]

- HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds [[arxiv](https://arxiv.org/abs/2308.10373)] [[paper with code](https://paperswithcode.com/paper/hosnn-adversarially-robust-homeostatic)]

- SpikingBERT: Distilling BERT to Train Spiking Language Models Using Implicit Differentiation [[arxiv](https://arxiv.org/abs/2308.10873)] [[paper with code](https://paperswithcode.com/paper/spikingbert-distilling-bert-to-train-spiking)] [[code](https://github.com/neurocomplab-psu/spikingbert)]

- Maintaining Plasticity in Continual Learning via Regenerative Regularization [[arxiv](https://arxiv.org/abs/2308.11958)] [[paper with code](https://paperswithcode.com/paper/maintaining-plasticity-via-regenerative)]

- Learning the Plasticity: Plasticity-Driven Learning Framework in Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.12063)] [[paper with code](https://paperswithcode.com/paper/metaplasticity-unifying-learning-and)]

- Privacy-Preserving Discretized Spiking Neural Networks [[arxiv](https://arxiv.org/abs/2308.12529)]

- A time multiscale based data-driven approach in cyclic elasto-plasticity [[arxiv](https://arxiv.org/abs/2308.12928)]

- TC-LIF: A Two-Compartment Spiking Neuron Model for Long-Term Sequential Modelling [[arxiv](https://arxiv.org/abs/2308.13250)] [[paper with code](https://paperswithcode.com/paper/tc-lif-a-two-compartment-spiking-neuron-model)] [[code](https://github.com/zhangshimin1/tc-lif)]

- SpikeBERT: A Language Spikformer Learned from BERT with Knowledge Distillation [[arxiv](https://arxiv.org/abs/2308.15122)] [[paper with code](https://paperswithcode.com/paper/spikebert-a-language-spikformer-trained-with)] [[code](https://github.com/Lvchangze/SpikeBERT)]

- Unleashing the Potential of Spiking Neural Networks for Sequential Modeling with Contextual Embedding [[arxiv](https://arxiv.org/abs/2308.15150)] [[paper with code](https://paperswithcode.com/paper/unleashing-the-potential-of-spiking-neural-1)]

- A Deep Dive into the Design Space of a Dynamically Reconfigurable Cryogenic Spiking Neuron [[arxiv](https://arxiv.org/abs/2308.15754)] [[paper with code](https://paperswithcode.com/paper/a-deep-dive-into-the-design-space-of-a)]

- Artificial to Spiking Neural Networks Conversion for Scientific Machine Learning [[arxiv](https://arxiv.org/abs/2308.16372)] [[paper with code](https://paperswithcode.com/paper/artificial-to-spiking-neural-networks)]

- Deep learning for spike detection in deep brain stimulation surgery [[arxiv](https://arxiv.org/abs/2308.05755)] [[paper with code](https://paperswithcode.com/paper/deep-learning-for-spike-detection-in-deep)]

- A comprehensive study of spike and slab shrinkage priors for structurally sparse Bayesian neural networks [[arxiv](https://arxiv.org/abs/2308.09104)] [[paper with code](https://paperswithcode.com/paper/a-comprehensive-study-of-spike-and-slab)]

- Adaptive whitening with fast gain modulation and slow synaptic plasticity [[arxiv](https://arxiv.org/abs/2308.13633)] [[paper with code](https://paperswithcode.com/paper/adaptive-whitening-with-fast-gain-modulation)] [[code](https://github.com/lyndond/multi_timescale_whitening)] [[openview](https://openreview.net/forum?id=vz7SdRqWGM)]

